{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9080a51",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d09504a",
   "metadata": {},
   "source": [
    "Cross validation is an important technique used in machine learning model evaluation and selection. Here’s a brief overview:\n",
    "\n",
    "    It is used to evaluate how the results of a statistical model will generalize to an independent dataset.\n",
    "\n",
    "    The dataset is divided into k number of groups known as folds. Typically k=5 or 10.\n",
    "\n",
    "    One fold is used as the validation set to evaluate the model, while the remaining k-1 folds are used to train the model.\n",
    "\n",
    "    This process is repeated k times, each time using a different fold as the validation set.\n",
    "\n",
    "    The validation results are then averaged over all k trials to get an overall cross-validation estimate of how the model is expected to perform.\n",
    "\n",
    "    This helps address overfitting – models that perform well only due to a particular dataset split.\n",
    "\n",
    "    Common types include k-fold CV, leave-one-out CV, stratified CV etc. depending on the problem.\n",
    "\n",
    "    It provides an almost unbiased estimation of model performance on unseen data without a separate hold-out test set.\n",
    "\n",
    "    Popular in model selection to choose hyperparameters that generalize better to new examples.\n",
    "\n",
    "So in summary, cross validation helps address overfitting and identify how well a model can classify or predict unknown examples. It is a standard evaluation technique in ML."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
