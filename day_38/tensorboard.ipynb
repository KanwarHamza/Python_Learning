{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "019b400e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tf_env\\lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaaeb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up log directory \"logs\" and a function that prepends the time of a run\n",
    "root_logdir = os.path.join(os.curdir, \"logs\")\n",
    "\n",
    "\n",
    "def get_run_logdir(name: str = \"\"):\n",
    "    \"\"\"\n",
    "    Prepends time of a run to the specified name of the run.\n",
    "    This new string (with time prepended) will be used as directory name.\n",
    "    \"\"\"\n",
    "    import time\n",
    "\n",
    "    run_id = time.strftime(\"%m_%d-%H_%M\")\n",
    "    run_name = run_id + f\"_{name}\"\n",
    "    return os.path.join(root_logdir, run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f359de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# load dataset (fmnist) - note: The dataset is reduced to allow for faster computations\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000] / 255, X_train_full[5000:35000] / 255\n",
    "y_valid, y_train = y_train_full[:5000]      , y_train_full[5000:35000]\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1fb293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some training hyperparams\n",
    "EPOCHS = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5161e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\tf_env\\lib\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "model1 = keras.models.Sequential(\n",
    "    [\n",
    "        layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "        layers.Conv2D(filters=32, kernel_size=3),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model1.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed3431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 21ms/step - accuracy: 0.7637 - loss: 0.6572 - val_accuracy: 0.8706 - val_loss: 0.3801\n",
      "Epoch 2/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.8784 - loss: 0.3281 - val_accuracy: 0.8900 - val_loss: 0.3119\n",
      "Epoch 3/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.8959 - loss: 0.2799 - val_accuracy: 0.8948 - val_loss: 0.2935\n",
      "Epoch 4/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 19ms/step - accuracy: 0.9100 - loss: 0.2414 - val_accuracy: 0.8996 - val_loss: 0.2847\n",
      "Epoch 5/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 20ms/step - accuracy: 0.9182 - loss: 0.2189 - val_accuracy: 0.8924 - val_loss: 0.3009\n",
      "Epoch 6/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9250 - loss: 0.2016 - val_accuracy: 0.8982 - val_loss: 0.2954\n",
      "Epoch 7/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9291 - loss: 0.1857 - val_accuracy: 0.8912 - val_loss: 0.3086\n",
      "Epoch 8/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9371 - loss: 0.1662 - val_accuracy: 0.8866 - val_loss: 0.3238\n",
      "Epoch 9/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 22ms/step - accuracy: 0.9419 - loss: 0.1556 - val_accuracy: 0.8996 - val_loss: 0.3212\n",
      "Epoch 10/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 21ms/step - accuracy: 0.9485 - loss: 0.1359 - val_accuracy: 0.9024 - val_loss: 0.2751\n",
      "Epoch 11/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9507 - loss: 0.1322 - val_accuracy: 0.9080 - val_loss: 0.2883\n",
      "Epoch 12/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 21ms/step - accuracy: 0.9573 - loss: 0.1172 - val_accuracy: 0.9036 - val_loss: 0.3221\n",
      "Epoch 13/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 22ms/step - accuracy: 0.9590 - loss: 0.1106 - val_accuracy: 0.9020 - val_loss: 0.3461\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: This is where the callback is defined and used\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(\n",
    "    get_run_logdir(\"1conv\"),\n",
    "    histogram_freq=1,\n",
    ")\n",
    "history = model1.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c745566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 2\n",
    "model2 = keras.models.Sequential(\n",
    "    [\n",
    "        layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
    "        layers.Conv2D(filters=32, kernel_size=3),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv2D(filters=32, kernel_size=3),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPool2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model2.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee54a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 23ms/step - accuracy: 0.7099 - loss: 0.8120 - val_accuracy: 0.8592 - val_loss: 0.3820\n",
      "Epoch 2/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.8552 - loss: 0.3978 - val_accuracy: 0.8786 - val_loss: 0.3247\n",
      "Epoch 3/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.8680 - loss: 0.3534 - val_accuracy: 0.8896 - val_loss: 0.3091\n",
      "Epoch 4/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 23ms/step - accuracy: 0.8773 - loss: 0.3303 - val_accuracy: 0.8748 - val_loss: 0.3274\n",
      "Epoch 5/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 22ms/step - accuracy: 0.8843 - loss: 0.3052 - val_accuracy: 0.8868 - val_loss: 0.3123\n",
      "Epoch 6/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 26ms/step - accuracy: 0.8947 - loss: 0.2817 - val_accuracy: 0.8620 - val_loss: 0.3608\n",
      "Epoch 7/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.8962 - loss: 0.2738 - val_accuracy: 0.8952 - val_loss: 0.2849\n",
      "Epoch 8/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 42ms/step - accuracy: 0.9041 - loss: 0.2570 - val_accuracy: 0.8962 - val_loss: 0.2859\n",
      "Epoch 9/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 38ms/step - accuracy: 0.9094 - loss: 0.2468 - val_accuracy: 0.9074 - val_loss: 0.2641\n",
      "Epoch 10/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.2391 - val_accuracy: 0.8956 - val_loss: 0.2893\n",
      "Epoch 11/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 38ms/step - accuracy: 0.9135 - loss: 0.2302 - val_accuracy: 0.9072 - val_loss: 0.2601\n",
      "Epoch 12/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 35ms/step - accuracy: 0.9165 - loss: 0.2195 - val_accuracy: 0.9048 - val_loss: 0.2572\n",
      "Epoch 13/13\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 23ms/step - accuracy: 0.9166 - loss: 0.2164 - val_accuracy: 0.9060 - val_loss: 0.2627\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT: This is where the callback is defined and used\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(\n",
    "    get_run_logdir(\"2conv\"),\n",
    "    histogram_freq=1,\n",
    ")\n",
    "history = model2.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    callbacks=[tensorboard_cb],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71666630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7132), started 0:08:36 ago. (Use '!kill 7132' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d3a1876073bff54f\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d3a1876073bff54f\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load tensorboard\n",
    "%load_ext tensorboard\n",
    "# start tensorboard inside the notebook. Outside of the notebook, \n",
    "# use tensorboard --logdir=./logs\n",
    "%tensorboard --logdir=./logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688b9af5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
